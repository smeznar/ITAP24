{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vaje 7: Nevronske mreže 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naloga 1: Usmerjene (feedforward) nevronske mreže "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z ukazom `pip3 install torch torchvision` si inštaliraj paket [PyTorch](https://pytorch.org/get-started/locally/), ki ga bomo uporabljali za nevronske mreže in ukazom `pip3 install tqdm` paket [tqdm](https://github.com/tqdm/tqdm), ki ga bomo uporabljali za izpisovanje sprotnih rezultatov\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transform\n",
    "from torchvision.datasets import MNIST\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naložimo podatkovno množico. Uporabljali bomo slike števk, za katere bomo poskusili napovedati, katera števka je na sliki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_set = MNIST('../Podatki/', train=True, download=True, \n",
    "                  transform=transform.Compose([transform.ToTensor(), transform.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "test_set = MNIST('../Podatki/', train=False, download=True, \n",
    "                 transform=transform.Compose([transform.ToTensor(), transform.Normalize((0.1307,), (0.3081,))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poglejmo si, kako naši podatki zgledajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prvi učni primer pretvorimo v numpy array in ga izrišemo\n",
    "first_image = train_set[0][0].numpy()[0, :, :]\n",
    "plt.imshow(first_image, cmap=\"Greys\")\n",
    "plt.show()\n",
    "\n",
    "# Vhodni podatki v usmerjeno nevronsko mrežo bodo vektorji. Zato sliko pretvorimo v vektor (lepimo vrstice eno za drugo). Za lepše viden izris ta vektor 100-krat skopiramo \n",
    "plt.imshow(np.repeat(first_image.reshape((28*28, 1)).T, repeats=100, axis=0), cmap=\"Greys\")\n",
    "plt.show()\n",
    "\n",
    "# Izpišemo ciljno vrednost prvega učnega podatka\n",
    "print(f\"Label {train_set[0][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sestavimo napovedni model, ga natrenirajmo in potestiramo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definirajmo našo nevronsko mrežo\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Definiramo objekt, ki bo sliko spremenil v vektor\n",
    "        self.flatten = nn.Flatten()\n",
    "        # Definiramo sloje naše nevronske mreže\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            # Polno povezan sloj z vhodno dimenzijo 28*28 in izhodno dimenzijo 64\n",
    "            nn.Linear(28*28, 64),\n",
    "            # Aktivacijska funkcija ReLu\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 20),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(20, 10)\n",
    "        )\n",
    "        # Definiramo še objekt, ki bo izhod pretvoril v \"verjetnosti\" (pozitivne vrednosti, ki se šeštejejo v 1)\n",
    "        # parameter dim=1 nam to naredi po drugi (1-ti) dimenziji. Vsak podatek po prvi (0-ti) dimenziji je ena slika v skupini (batchu)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Vhodno sliko pretvorimo v vektor\n",
    "        x = self.flatten(x)\n",
    "        # Vektor pošljemo čez vse sloje in aktivacijske vrednosti\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        # Izhod iz nevronske mreže pretvorimo v \"verjetnosti\" za vsako ciljno vrednost\n",
    "        return self.softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naredimo funkcijo, ki bo natrenirala naš model\n",
    "def train(epochs, model, trainset, batch_size, learning_rate=0.01):\n",
    "    \n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Zagotovimo, da bo model v načinu treniranja, kjer se računajo gradienti in so aktivni vsi sloji (med evalvacijo niso nujno vsi aktivni, npr. Dropout, BatchNormalization, ...)\n",
    "    model.train()\n",
    "    \n",
    "    # Definiramo naš optimizator. V našem primeru bo to stohastični gradientni spust (SGD) z learning rate-om 0.01\n",
    "    # Lahko bi uporabili tudi Adam naprimer\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # Definiramo našo funkcijo izgube (loss). V našem primeru bo to prečna entropija.\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Gremo čež epohe\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        # Uporabimo funkcijo tqdm.tqdm, ki nam bo lepše, v realnem času izpisovala napredek učenja\n",
    "        with tqdm(total=len(trainloader)*batch_size, desc=f'Training - Epoch: {epoch + 1}/{epochs}', unit='chunks') as prog_bar:\n",
    "            # Gremo čez vse podatke v skupinah po batch_size z trainloaderjem, v našem primeru je to 32\n",
    "            for i, data in enumerate(trainloader, 0):\n",
    "                # Podatke razpakiramo v vhode in izhode (labele)\n",
    "                inputs, labels = data\n",
    "\n",
    "                # Počistimo (resetiramo) gradiente v podatkih\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Vhodne podatke spustimo čez model, ta nam vrne matriko, v kateri se vsaka vrstica sešteje v 1 (zaradi Softmax sloja)\n",
    "                outputs = model(inputs)\n",
    "                # Izračunamo izgubo\n",
    "                loss = criterion(outputs, labels)\n",
    "                # Naredimo vzvratno razširanje napake (backpropagation)\n",
    "                loss.backward()\n",
    "                # Naredimo en korak optimizacije\n",
    "                optimizer.step()\n",
    "\n",
    "                # Dodamo izgubo k naši vsoti izgube. S funkcijo detach poskrbimo, da ne prištejemo (in si tako shranimo) tudi gradienta\n",
    "                # s funkcijo item() pa da se le vrednost in ne celoten vektor\n",
    "                running_loss += loss.detach().item()\n",
    "\n",
    "                # Posodobimo vrednosti funkcije tqdm.tqdm. Vsoto dosedanje izgube delimo s številom skupin, ki smo jih že obdelali\n",
    "                prog_bar.set_postfix(**{'loss': (running_loss) / (i+1)})\n",
    "                # Posodobimo progress bar\n",
    "                prog_bar.update(batch_size)\n",
    "\n",
    "    print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testset, batch_size):\n",
    "    \n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Model damo v način evalvacije. Tu se gradienti ne računajo in da se nekateri sloji deaktivirajo\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    counter = 0\n",
    "    \n",
    "    # Dodatno poskrbimo, da vektorji ne vsebujejo gradientov\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(testloader)*batch_size, desc=f'Testing', unit='chunks') as prog_bar:\n",
    "            for i, data in enumerate(testloader, 0):\n",
    "                inputs, labels = data\n",
    "                output = model(inputs)\n",
    "                test_loss += criterion(output, labels).detach().item()\n",
    "                # Izberemo indekse mesta z najvišjo vrednostjo (\"verjetnostjo\")\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                # Prištejemo število primerov, kjer smo zadeli pravilno števko\n",
    "                correct += pred.eq(labels.data.view_as(pred)).sum()\n",
    "                prog_bar.update(batch_size)\n",
    "                counter += 1\n",
    "    \n",
    "    print(f'Test set: Avg. loss: {test_loss/counter}, Correct predictions: {correct}/{len(testloader.dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = NeuralNetwork()\n",
    "epochs = 5\n",
    "\n",
    "print(\"Accuracy on the test set before training\")\n",
    "print(end=\"\")\n",
    "test(model, test_set, batch_size)\n",
    "print()\n",
    "\n",
    "train(epochs, model, train_set, batch_size)\n",
    "print()\n",
    "\n",
    "print(\"Accuracy on the test set after training the model\")\n",
    "test(model, test_set, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.a: Preveri število parametrov v natreniranem modelu. Pomagaj si z modelovo funkcijo `parameters()` in funkcijo tenzorja `numel()`, ki izpiše število vrednosti znotraj tenzorja. Kako se število parametrov primerja z dosedaj videnimi napovednimi modeli in kaj predstavljajo vmesne vrednosti na sodih mestih?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.b: Spremeni zgornjo nevronsko mrežo tako, da ji dodaš še en polno-povezan sloj in spremeni srednjo aktivacijsko funkcijo iz ReLu v Tanh in preveri njeno točnost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.c: Preiskusi točnost nevronske mreže z različnimi velikosti skupin (batch-ev), optimizatorji (SGD in Adam) in različnimi hitrostmi učenja (learning rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Subset\n",
    "train_subset = Subset(train_set, range(5000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naloga 2: Konvolucijska nevronska mreža"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.a: S pomočjo 2D konvolucijskega sloja ([`nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)) in maxpool sloja ([`nn.MaxPool2d`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)) sestavi konvolucijsko nevronsko mrežo in jo potestiraj na testni množici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.b: Izpiši število parametrov te nevronske mreže. Kako se število parametrov razlikuje od števila parametrov usmerjene nevronske mreže?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.c: Modelu dodaj še en konvolucijski sloj in maxpooling sloj, ga natreniraj, preveri njegovo točnost na testni množici in preveri koliko parametrov ima. Opaziš kaj nenavadnega?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naloga 3: Eksperimenti z nevronskimi mrežami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.a: Poigraj se z naslednjimi parametri, da dobiš čim boljši model:\n",
    "- število konvolucijskih slojev v mreži\n",
    "- število polno-povezanih slojev v mreži\n",
    "- velikost jedra konvolucijskega sloja\n",
    "- velikost jedra maxpool sloja\n",
    "- število nevronov v polno povezanih slojih\n",
    "- število izhodnih kanalov konvolucijskega sloja\n",
    "- hitrost učenja\n",
    "- optimizator (Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.b: Opiši, kako bi z nevronsko mrežo sestavil model linearne regresije, ki se parametrov nauči iterativno in ne eksaktno."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
