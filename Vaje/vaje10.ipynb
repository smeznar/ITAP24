{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vaje 10: Krčenje razsežnosti podatkov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naloga 1: Rangiranje podatkov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Najprej se bomo ukvarjali z rangiranjem in izbiro spremenljivk. Za rangiranje spremenljivk moramo najprej oceniti njihovo pomembnost. Rangiranje in ocenjevanje pomembnosti spremenljivk je zanimivo že za interpretacijo podatkov, uporabno pa je tudi za učenje napovednih modelo, na primer za izbiro manjše množice pomembnih spremenljivk, ali pa za uteževanje spremenljivk pri učenju modelov.\n",
    "\n",
    "Obstaja veliko metod za ocenjevanje pomembnosti spremenjivk. Ločimo jih po tem, ali izhajajo iz napovednega modela (kot na primer pomembnosti pri drevesnih modelih). \n",
    "Metode, ki so od modelov neodvisne, dalje ločimo na nadzorovane in nenadzorovane glede na to, ali upoštevajo ciljno spremenljivko.\n",
    "\n",
    "Ker izbira spremenljivk vpliva na izbiro napovednega modela je zelo pomembno, da pomembnost spremenljivk ocenjujemo le na učni množici."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.a: Preberi podatke iz datoteke `vaje10.npz` in jih razdeli v učno in testno množico. Učna množica naj vsebuje približno 80% podatkov, testna pa preostale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Začnimo z najpreprostejšo, nenadzorovano metodo, pri kateri za pomembnejše spremenljivke označimo tiste z višjo varianco.\n",
    "\n",
    "(Opomba: v primeru kategoričnih spremenljivk se računa entropija.)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.b: Učne podatke skaliraj na interval [0, 1] in izračunaj varianco vsake spremenljivke. Izračunaj rangiranje spremenljivk ter nariši rangirni graf (x-os: spremenljivke urejene po padajoči pomembnosti, y-os: pomembnost spremenljivk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naslednja metoda je primer nadzorovane metode ocenjevanja pomembnosti na podlagi statističnega testa. Ker pri tej metodi ignoriramo povezave med različnimi stolpci, spada med uni-variantne metode.\n",
    "\n",
    "V naših podatkih so vsi X numerični, Y pa je dvojiški, tako da bo ustrezen test *Welchov t-test*, ki ga v scipy-ju lahko najdemo pod imenom `scipy.stats.ttest_ind` s parametrom `equal_var=False`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.c: Učno množico razdeli na množici pozitivnih in negativnih primerov in za vsako spremenljivko izračunaj pomembnost z \"Welchovim t-testom\" (nižja p-vrednost => spremenljivka je bolj pomembna). Izračunaj rangiranje spremenljivk ter nariši rangirni graf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zadnja metoda, ki jo bomo preizkusili, je algoritem *Relief*. Gre za popularno metodo, ki upošteva tudi interakcije med napovednimi spremenljivkami (Višja vrednost => bolj pomembna spremenljivka)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.d: S pomočjo knjižnjice [`sklearn-relief`](https://gitlab.com/moongoal/sklearn-relief) izračunaj pomembnost spremenljivk z algoritmom Relief ali RReliefF, jih rangiraj in nariši rangirni graf. \n",
    "\n",
    "<details>\n",
    "  <summary>Namig:</summary>\n",
    "\n",
    "  *Vhodni podatki v algoritem RReliefF morajo biti skalirani na interval [0,1]. Knjižnjica `sklearn-relief` uporablja isti uporabniški vmesnik kot sklearn zato lahko pomembnost spremenljivk ocenimo z metodo fit, podatke pa spremenimo iz originalnega prostora v preslikan prostor z metodo transform. Pomembnost spremenljivk lahko najdemo v spremenljivki w_*.\n",
    "\n",
    "  ```\n",
    "  import sklearn_relief\n",
    "  relief = sklearn_relief.Relief(n_features=10)\n",
    "  ...\n",
    "  print(relief.w_)\n",
    "  ``` \n",
    "   \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sklearn-relief"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.e: Izberi 10 najbolj pomembnih spremenljiv glede na ocene pomembnosti iz nalog 1.b, 1.c in 1.d. Za vsako podmnožico spremenljivk preveri točnost odločitvenih dreves na testni množici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naloga 2: Metoda glavnih komponent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Krčenje razsežnosti podatkov smo si na hitro pogledali že na drugih vajah o nevronskih mrežah (samokodirnik) in na vajah o gručenju (TSNE). Sedaj si bomo pogledali še najbolj popularno metodo za transformacijo podatkov v prostor nižje razsežnosti, metodo glavnih komponent (PCA - principle component analysis). Prva glavna komponenta je linearna kombinacija napovednih spremenljivk, ki povzame največ variance v podatkih. Druga glavna komponenta je pravokotna na prvo ter povzame največ variance v podatkih ki ostanejo, ko jim odstranimo prvo komponento. Z nadaljevanjem postopka pridobimo p komponent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pri metodi PCA ponavadi rišemo graf \"scree\". Na x-osi ima glavne komponente, na y-osi pa delež variance, ki ga vsaka glavna komponenta pojasni.\n",
    "Pogosto je lažje berljiv graf kumulativne variance, kjer za i-to glavno komponento na y-osi narišemo delež variance,\n",
    "ki ga skupaj pojasnijo vse komponente do vključno i-te."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.a: Izračunaj glavne komponente in nariši \"scree\" graf z dvema krivuljama: Delež pojasnjene variance in komulativni delež pojasnjene variance.\n",
    "\n",
    "<details>\n",
    "  <summary>Namig:</summary>\n",
    "\n",
    "  *Pomagaš si lahko z [objektom sklearn.decomposition.PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)* in atributom `explained_variance_ratio_`, ki vsebuje seznam z deleži pojasnjene variance za vsako glavno komponento.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.b: Metoda glavnih komponent se včasih uporablja tudi za vizualizacijo visoko dimenzionalnih podatkov. Nariši graf, ki ima na x-osi vrednosti prve glavne komponente, na y-osi pa vrednosti druge glavne komponente. Uporabi skalirane podatke, logaritemsko skalo in z različnima barvama loči pozitivne in negativne primere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Končno uporabimo PCA še za učenje napovednega modela. Kot napovedne spremenljivke modelu namesto originalnih podatkov podamo M glavnih komponent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.c: Izračunaj točnost modela odločitvenih dreves na originalnem in na transformiranem prostoru. Pri kakšnem številu glavnih komponent je točnost modela najvišja?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V praksi število komponent izberemo glede z uporabo \"scree\" grafa. Pogledamo pri katerem številu komponent delež pojasnjene variance neha bistveno naraščati oziroma izberemo število komponent pri katerem smo zadovoljni z razmerjem med deležem in številom komponent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glavna omejitev metode glavnih kompoment je njena linearnost. \n",
    "Nekaj popularnih nelinearnih metod za krčenje razsežnosti podatkov:\n",
    "- samokodirniki\n",
    "- t-SNE\n",
    "- UMAP\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ITAP24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
