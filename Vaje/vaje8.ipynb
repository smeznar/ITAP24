{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vaje 8: Nevronske mreže 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naloga 1: Samokodirniki"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naloga samokodirnikov je podatke \"stisnit\" oz vpet (to boste kasneje delali na predavanjih) v prostor nižje dimenzije (imenovan tudi latentni prostor). Podatke tako preslikajo v latentni prostor in nazaj v originalen prostor. Pri tem je cilj, da se originalni podatki in rekonstruirani podatki čim bolj skladajo (oz. imamo nizko rekonstrukcijsko napako).\n",
    "\n",
    "Poglejmo si primer samokodirnika na primeru od zadnjič; slikah ročno napisanih števk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.datasets import MNIST\n",
    "import torchvision.transforms as transform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = MNIST('../Podatki/', train=True, download=True, \n",
    "                  transform=transform.Compose([transform.ToTensor(), transform.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "# Naložimo testno množico, slike pretvorimo v tenzorje in jih standardiziramo\n",
    "test_set = MNIST('../Podatki/', train=False, download=True, \n",
    "                 transform=transform.Compose([transform.ToTensor(), transform.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "batch_size = 128\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.a: Dopolni nevronski mreži `Encoder` (kodirnik) in `Decoder` (dekodirnik). Kodirnik bo sliko zakodiral v latentni prostor, Dekodirnik pa bo sliko dekodiral iz latentnega prostora nazaj v originalen prostor (prostor slik).\n",
    "\n",
    "Kodirnik naj vsebuje tri konvolucijske sloje (s 8, 16 in 32 izhodnih kanalov, konvolucijskim jedrom 3, stride 2 in prva dva padding 1, zadnji 0) in dva polno povezana sloja (prvi z vhodno dimenzijo 3*3*32 in izhodno dimenzijo 128 in drugi z izhodno dimenzijo `latent_dimension`). Kjer je smiselno dodaj aktivacijsko funkcijo ReLu, takoj za drugim konvolucijskim slojem BatchNorm2d sloj (s parametrom 16) in pred prvim polno-povezanim slojem ne pozabim slike spremeniti v vektor (uporabi parameter start_dim=1)\n",
    "\n",
    "Dekodirnik naj vsebuje iste sloje, a v obratni smeri. Tu namesto Conv2D uporabi ConvTranspose2d in poleg parametra padding nastavi še parameter output_padding (na isto vrednost). Za drugim polno-povezanim slojem vektor pretvori v slike z nn.Unflatten (dim=1, unflatten_size=(32, 3, 3))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dimension):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder_cnn = nn.Sequential(\n",
    "            # Dopolni\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.encoder_cnn(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dimension):\n",
    "        super().__init__()\n",
    "        self.decoder_cnn = nn.Sequential(\n",
    "            # Dopolni\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.decoder_cnn(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modela natreniraj. To lahko traja nekaj minut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "lr= 0.001\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "encoder = Encoder(latent_dimension=5)\n",
    "decoder = Decoder(latent_dimension=5)\n",
    "params_to_optimize = [\n",
    "    {'params': encoder.parameters()},\n",
    "    {'params': decoder.parameters()}\n",
    "]\n",
    "\n",
    "optim = torch.optim.Adam(params_to_optimize, lr=lr, weight_decay=1e-05)\n",
    "\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    encoder.train()\n",
    "    decoder.train()\n",
    "    train_loss = []\n",
    "    for image_batch, _ in train_loader:\n",
    "        encoded_data = encoder(image_batch)\n",
    "        decoded_data = decoder(encoded_data)\n",
    "        loss = loss_fn(decoded_data, image_batch)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        train_loss.append(loss.detach().cpu().numpy())\n",
    "    print(f\"Epoch {epoch}, loss: {np.mean(train_loss)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.b: Poglejmo si kako dobro model slike rekonstruira. V spodnji kodi dopolni vrstico, s katero dobimo rekonstruirano sliko."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,4.5))\n",
    "targets = test_set.targets.numpy()\n",
    "t_idx = {i: np.where(targets==i)[0][0] for i in range(10)}\n",
    "\n",
    "for i in range(10):\n",
    "    ax = plt.subplot(2, 10, i+1)\n",
    "    img = test_set[t_idx[i]][0].unsqueeze(0)\n",
    "    encoder.eval()\n",
    "    decoder.eval()\n",
    "    plt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)  \n",
    "    if i == 5:\n",
    "        ax.set_title('Original images')\n",
    "    ax = plt.subplot(2, 10, i + 11)\n",
    "    with torch.no_grad():\n",
    "        rec_img  = # Dopolni (lahko v večih vrsticah)\n",
    "    plt.imshow(rec_img.cpu().squeeze().numpy(), cmap='gist_gray')  \n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)  \n",
    "    if i == 5:\n",
    "        ax.set_title('Reconstructed images')\n",
    "plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.c: Poglejmo si še, kako se slike gručijo oz. kam v latentni prostor se preslikajo. Dopolni vrstico, v kateri sliko zakodiraš v latentni prostor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_samples = []\n",
    "for sample in test_set:\n",
    "    img = sample[0].unsqueeze(0)\n",
    "    label = sample[1]\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_img  = # Dopolni\n",
    "    encoded_img = encoded_img.flatten().cpu().numpy()\n",
    "    encoded_sample = {f\"Enc. Variable {i}\": enc for i, enc in enumerate(encoded_img)}\n",
    "    encoded_sample['label'] = label\n",
    "    encoded_samples.append(encoded_sample)\n",
    "encoded_samples = pd.DataFrame(encoded_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z uporabo metode TSNE lahko podatke (nelinearno) preslikamo v še nižjo dimenzijo in jih tako vizualiziramo. Kaj lahko opaziš na spodnjih slikah in ali si to pričakoval?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2)\n",
    "tsne_results = tsne.fit_transform(encoded_samples.drop(['label'],axis=1))\n",
    "labels = encoded_samples[\"label\"].to_numpy()\n",
    "\n",
    "for i in range(10):\n",
    "    indices = labels == i\n",
    "    fig = plt.scatter(tsne_results[indices, 0], tsne_results[indices, 1], c=[plt.get_cmap(\"tab10\").colors[i] for j in range(np.sum(indices))], label=i)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=3)\n",
    "tsne_results = tsne.fit_transform(encoded_samples.drop(['label'],axis=1))\n",
    "labels = encoded_samples[\"label\"].to_numpy()\n",
    "\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "for i in range(10):\n",
    "    indices = labels == i\n",
    "    fig = ax.scatter(tsne_results[indices, 0], tsne_results[indices, 1], tsne_results[indices, 2], c=[plt.get_cmap(\"tab10\").colors[i] for j in range(np.sum(indices))], label=i)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.d: Vidimo lahko torej, da so podatki z isto cilno vrednostjo, pogosto preslikani blizu v latentnem prostoru. S preslikanimi podatki si torej lahko pomagamo pri klasifikaciji. S spodnjo kodo podatke zakodiramo v latentni prostor in jih spremenimo v numpy array. Na podoben način pripravi testno množico in na njej preveri točnost napovednega modela SVM (SVC v sklearn-u) naučenega na učni množici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "train_y = []\n",
    "\n",
    "for sample in train_set:\n",
    "    img = sample[0].unsqueeze(0)\n",
    "    train_y.append(sample[1])\n",
    "    encoder.eval()\n",
    "    with torch.no_grad():\n",
    "        encoded_img  = encoder(img)\n",
    "    train_x.append(encoded_img.flatten().cpu().numpy())\n",
    "\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naloga 2: Rekurenčne nevronske mreže (GRU) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.a: Dopolni funkcijo `create_sequences`, ki sprejme časovno vrsto dolžine N ter parameter M (seq_length) in zgenerira N-M zaporedij dolžine M (torej prvo od indeksa 0 do indeksa M, drugo od 1 do M+1, itd.). Seznam sequences naj na koncu vsebuje 2-terice zaporedje, ciljna vrednost (naslednja vrednost v zaporedju)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.linspace(0,799,400)\n",
    "y = torch.sin(x*2*np.pi/40) \n",
    "\n",
    "test_size = 100\n",
    "train_data = y[:-test_size]\n",
    "test_data = y[-test_size:]\n",
    "\n",
    "def create_sequences(data, seq_length):\n",
    "    sequences = []\n",
    "    # Dopolni\n",
    "    return sequences\n",
    "\n",
    "seq_length = 20\n",
    "train_sequences = create_sequences(train_data, seq_length)\n",
    "\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.a: Dopolni spodnjo kodo, ki definira [GRU celico](https://pytorch.org/docs/stable/generated/torch.nn.GRUCell.html). Vektor (matrika) h naj bo poljubne velikosti, izhodni vektor pa naj bo dobljen tako, da h pošlješ čez polno-povezan sloj ustreznih dimenzij. Sloje, ki jih boš potreboval/a lahko najdeš z uporabo nn.ImeSloja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(GRU, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        # Dopolni\n",
    "\n",
    "\n",
    "    def forward(self, X):\n",
    "        output = []\n",
    "        h = torch.zeros(self.hidden_size)\n",
    "        for t in range(X.shape[0]):\n",
    "            # Dopolni\n",
    "            output += [out]\n",
    "\n",
    "        output = torch.stack(output)\n",
    "        return output[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model natreniraj in potestiraj na testnih podatkih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GRU(1, 10, 1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000001)\n",
    "\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch \", epoch)\n",
    "    total_loss = 0\n",
    "    for i, (seq, labels) in enumerate(train_sequences):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(seq)\n",
    "        loss = criterion(y_pred, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.detach().item()\n",
    "    print(f\"Loss {total_loss/len(train_sequences)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Točnost modela za napovedovanje numeričnih spremenljivk lahko ocenimo tudi z ($r^2$)[https://en.wikipedia.org/wiki/Coefficient_of_determination] metriko, ki nam pove koliko variance lahko z našim modelom napovemo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = train_data[-seq_length:].tolist()\n",
    "model = model.eval()\n",
    "for i in range(test_size):\n",
    "    seq = torch.FloatTensor(test_inputs[-seq_length:])\n",
    "    with torch.no_grad():\n",
    "        res = model(seq)\n",
    "        test_inputs.append(res.item())\n",
    "\n",
    "print(r2_score(test_data.numpy(), test_inputs[seq_length:]))\n",
    "\n",
    "actual_predictions = test_inputs[seq_length:]\n",
    "plt.plot(y.data.numpy()[-test_size:])\n",
    "plt.plot(actual_predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.c: Poišči vrednosti parametrov \"learning_rate\" in \"hidden_size\" pri katerih bo model dobro deloval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.d: Na podoben način sestavi novo podatkovno množico za časovno vrsto, ki je definirana s funkcijo $0.5\\cdot\\sin (2\\cdot x\\cdot\\pi /40)+ \\sin (2\\cdot x\\cdot\\pi /400)$. Najdi model, ki bo tudi na teh podatkih dobro deloval. Pomagaš si lahko tako, da združiš več GRU celic ali pa sestaviš \"močnejšo\" LSTM celico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
